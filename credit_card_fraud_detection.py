# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection(Piyush).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wfZXhJ6oSMr2zoKU74Fsboh1kch4AgR6

# **Credit Card Fraud Detection**

IMPORTING LIBRARIES
"""

import numpy as np 
import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt  
from matplotlib import gridspec

df = pd.read_csv("/content/drive/My Drive/Credit Card Fraud Detection dataset/creditcard.csv")
df.head()

df.shape

df.info()

corrmat = df.corr() 
fig = plt.figure(figsize = (12, 9)) 
sns.heatmap(corrmat, vmax = .8, square = True) 
plt.show()

fraud = df[df['Class']==1]
valid = df[df['Class']==0]
print('Fraud Transactions: {}'.format(len(fraud)))
print('Valid Transactions: {}'.format(len(valid)))

X = df.drop(['Class'], axis = 1) 
y = df["Class"]

"""SPLITTING DATA"""

from sklearn.model_selection import train_test_split 
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=10)

"""RANDOM FOREST"""

#MODEL
from sklearn.ensemble import RandomForestClassifier 
model = RandomForestClassifier() 
model.fit(X_train, y_train) 
yPred = model.predict(X_test)

#EVALUATING
from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,recall_score,classification_report,precision_score
print('Accuracy Score:{}'.format(accuracy_score(y_test, yPred)))
print('f1 Score:{}'.format(f1_score(y_test, yPred)))
print('Recall Score:{}'.format(recall_score(y_test,yPred)))
print('Precison Score:{}'.format(precision_score(y_test,yPred)))
print('Classification Report:')
print(classification_report(y_test,yPred))

#CONFUSION MATRIX
labels = ['Normal', 'Fraud'] 
conf_matrix = confusion_matrix(y_test, yPred) 
plt.figure(figsize =(12, 12)) 
sns.heatmap(conf_matrix, xticklabels = labels, yticklabels = labels, annot = True, fmt ="d"); 
plt.title("Confusion matrix") 
plt.ylabel('True class') 
plt.xlabel('Predicted class') 
plt.show()

"""LOGISTIC REGRESSION"""

#MODEL
from sklearn.linear_model import LogisticRegression
log_reg=LogisticRegression(max_iter=1000)
log_reg.fit(X_train,y_train.values.ravel())
log_pred=log_reg.predict(X_test)

#EVALUATING
print('Accuracy Score:{}'.format(accuracy_score(y_test, log_pred)))
print('f1 Score:{}'.format(f1_score(y_test, log_pred)))
print('Recall Score:{}'.format(recall_score(y_test,log_pred)))
print('Precison Score:{}'.format(precision_score(y_test,log_pred)))
print('Classification Report:')
print(classification_report(y_test,log_pred))

#CONFUSION MATRIX
labels = ['Normal', 'Fraud'] 
conf_matrix = confusion_matrix(y_test, log_pred) 
plt.figure(figsize =(12, 12)) 
sns.heatmap(conf_matrix, xticklabels = labels, yticklabels = labels, annot = True, fmt ="d"); 
plt.title("Confusion matrix") 
plt.ylabel('True class') 
plt.xlabel('Predicted class') 
plt.show()

"""DECISION TREE"""

#MODEL
from sklearn.tree import DecisionTreeClassifier
dst=DecisionTreeClassifier()
dst.fit(X_train,y_train)
dst_pred=dst.predict(X_test)

#EVALUATING
print('Accuracy Score:{}'.format(accuracy_score(y_test, dst_pred)))
print('f1 Score:{}'.format(f1_score(y_test, dst_pred)))
print('Recall Score:{}'.format(recall_score(y_test,dst_pred)))
print('Precison Score:{}'.format(precision_score(y_test,dst_pred)))
print('Classification Report:')
print(classification_report(y_test,dst_pred))

#CONFUSION MATRIX
labels = ['Normal', 'Fraud'] 
conf_matrix = confusion_matrix(y_test, dst_pred) 
plt.figure(figsize =(12, 12)) 
sns.heatmap(conf_matrix, xticklabels = labels, yticklabels = labels, annot = True, fmt ="d"); 
plt.title("Confusion matrix") 
plt.ylabel('True class') 
plt.xlabel('Predicted class') 
plt.show()

"""SVM"""

#MODEL
from sklearn.svm import SVC
svm=SVC()
svm.fit(X_train,y_train.values.ravel())
svm_pred=svm.predict(X_test)

#REMOVE WARNING
import warnings
warnings.filterwarnings('ignore')

#EVALUATING
print('Accuracy Score:{}'.format(accuracy_score(y_test, svm_pred)))
print('f1 Score:{}'.format(f1_score(y_test, svm_pred)))
print('Recall Score:{}'.format(recall_score(y_test,svm_pred)))
print('Precison Score:{}'.format(precision_score(y_test,svm_pred)))
print('Classification Report:')
print(classification_report(y_test,svm_pred))

#CONFUSION MATRIX
labels = ['Normal', 'Fraud'] 
conf_matrix = confusion_matrix(y_test, svm_pred) 
plt.figure(figsize =(12, 12)) 
sns.heatmap(conf_matrix, xticklabels = labels, yticklabels = labels, annot = True, fmt ="d"); 
plt.title("Confusion matrix") 
plt.ylabel('True class') 
plt.xlabel('Predicted class') 
plt.show()